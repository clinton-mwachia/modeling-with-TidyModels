---
title: "Case Study"
author: "clinton moshe"
date: "11/23/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The Libraries

```{r}
library(tidymodels)
library(tidyverse)
library(vip)
```

## The Data

```{r}
hotels <- read_csv('data/hotels.csv')
head(hotels)
```

### Data Structure

```{r}
glimpse(hotels)
```

### Character to factors

```{r}
hotels <- hotels %>%
  mutate_if(is.character, as.factor)
```

### Response variable

```{r}
hotels %>%
  group_by(children) %>%
  count()
```

### Data Splitting & Resampling

```{r}
set.seed(123)
splits      <- initial_split(hotels, strata = children)

hotel_train <- training(splits)
hotel_test  <- testing(splits)

# validation data
set.seed(234)
val_set <- validation_split(hotel_train, 
                            strata = children, 
                            prop = 0.80)
val_set
```

## Modelling

### PENALIZED LOGISTIC REGRESSION

#### The model

```{r}
lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")
lr_mod
```

#### The Recipe

```{r}
holidays <- c("AllSouls", "AshWednesday", "ChristmasEve", "Easter", 
              "ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")

lr_recipe <- 
  recipe(children ~ ., data = hotel_train) %>% 
  step_date(arrival_date) %>% 
  step_holiday(arrival_date, holidays = holidays) %>% 
  step_rm(arrival_date) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())
lr_recipe
```

#### Workflow

```{r}
lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)
lr_workflow
```

#### Grid for model Tuning

```{r}
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))
lr_reg_grid
```

#### Model Training

```{r}
lr_res <- 
  lr_workflow %>% 
  tune_grid(val_set,
            grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
```

#### Model Metrics

```{r}
lr_res %>% 
  collect_metrics() 
```

#### Metrics Plot

```{r}
lr_plot <- 
  lr_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC Curve") +
  scale_x_log10(labels = scales::label_number())

lr_plot
```


#### Best Model by ROC_AUC

```{r}
top_models <-
  lr_res %>% 
  show_best("roc_auc", n = 15) %>% 
  arrange(penalty) 
top_models
```


```{r}
lr_best <- 
  lr_res %>% 
  collect_metrics() %>% 
  arrange(penalty) %>% 
  slice(12)
lr_best
```

```{r}
lr_res %>% 
  collect_predictions(parameters = lr_best)
```

```{r}
lr_auc <- 
  lr_res %>% 
  collect_predictions(parameters = lr_best) %>% 
  roc_curve(children, .pred_children) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)
```

### ENSEMBLE MODEL

#### The number of cores available

```{r}
cores <- parallel::detectCores()
cores
```

#### The model

```{r}
rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 10) %>% 
  set_engine("ranger", num.threads = cores) %>% 
  set_mode("classification")
rf_mod
```

#### The Recipe

```{r}
rf_recipe <- 
  recipe(children ~ ., data = hotel_train) %>% 
  step_date(arrival_date) %>% 
  step_holiday(arrival_date) %>% 
  step_rm(arrival_date) 
```

#### Workflow

```{r}
rf_workflow <- 
  workflow() %>% 
  add_model(rf_mod) %>% 
  add_recipe(rf_recipe)
rf_workflow
```


```{r}
set.seed(345)
rf_res <- 
  rf_workflow %>% 
  tune_grid(val_set,
            grid = 25,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
rf_res
```

```{r}
rf_res %>% 
  show_best(metric = "roc_auc")
```

```{r}
autoplot(rf_res)
```

##### Best Model

```{r}
rf_best <- 
  rf_res %>% 
  select_best(metric = "roc_auc")
rf_best
```

```{r}
rf_res %>% 
  collect_predictions()
```


```{r}
rf_auc <- 
  rf_res %>% 
  collect_predictions(parameters = rf_best) %>% 
  roc_curve(children, .pred_children) %>% 
  mutate(model = "Random Forest")
```


```{r}
bind_rows(rf_auc, lr_auc) %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_viridis_d(option = "plasma", end = .6)
```

## Final fit

```{r}
last_rf_mod <- 
  rand_forest(mtry = 5, min_n = 35, trees = 10) %>% 
  set_engine("ranger", num.threads = cores, importance = "impurity") %>% 
  set_mode("classification")

last_rf_workflow <- 
  rf_workflow %>% 
  update_model(last_rf_mod)

set.seed(345)
last_rf_fit <- 
  last_rf_workflow %>% 
  last_fit(splits)

last_rf_fit
```

### Metrics

```{r}
last_rf_fit %>% 
  collect_metrics()
```

```{r}
last_rf_fit %>% 
  pluck(".workflow", 1) %>%   
  extract_fit_parsnip() %>% 
  vip(num_features = 20)
```

### ROC CURVE

```{r}
last_rf_fit %>% 
  collect_predictions() %>% 
  roc_curve(children, .pred_children) %>% 
  autoplot()
```

